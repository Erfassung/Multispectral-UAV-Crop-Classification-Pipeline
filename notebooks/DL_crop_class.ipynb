{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "YlRXoY0FeFEj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDAfWH5Gd3IM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import platform\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision.models import resnet50\n",
        "import torchvision.transforms.functional as TF\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Device Configuration"
      ],
      "metadata": {
        "id": "yLyc1zkUeRIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  # Enable synchronous CUDA for better error reporting\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "if str(device) == \"cuda:0\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "GFhxoU8EeWqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load CSV and prepare dataset splits"
      ],
      "metadata": {
        "id": "odlAMocteiwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = 'stacked_patches_npy2/stacked_arrays_split_fixed_stride.csv'\n",
        "output_dir = './'\n",
        "output_suffix = '_final.csv'\n",
        "\n",
        "print(\"Loading pre-split CSV file...\")\n",
        "df = pd.read_csv(csv_path)\n",
        "print(f\"Total samples: {len(df)}\")\n",
        "\n",
        "# Extract class from filename (e.g., '1000_class7.npy' -> 7)\n",
        "df['class'] = df['output_file'].str.extract(r'_class(\\d+)\\.npy')[0].astype(int)\n",
        "\n",
        "print(\"Columns in CSV:\", df.columns.tolist())\n",
        "print(\"First few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nOriginal class distribution:\")\n",
        "print(df['class'].value_counts().sort_index())\n",
        "\n",
        "# Remove classes 0, 1, and 2\n",
        "original_count = len(df)\n",
        "df = df[df['class'] >= 3].copy()\n",
        "filtered_count = len(df)\n",
        "print(f\"\\nRemoved {original_count - filtered_count} samples (classes 0–2).\")\n",
        "print(f\"Remaining samples: {filtered_count}\")\n",
        "\n",
        "# Remap classes 3–7 to 0–4\n",
        "class_mapping = {3: 0, 4: 1, 5: 2, 6: 3, 7: 4}\n",
        "df['label'] = df['class'].map(class_mapping)\n",
        "\n",
        "# Use original filename for consistency\n",
        "df['filename'] = df['output_file']\n",
        "\n",
        "print(f\"\\nApplied class mapping: {class_mapping}\")\n",
        "print(f\"Original classes: {sorted(df['class'].unique())}\")\n",
        "print(f\"Mapped labels: {sorted(df['label'].unique())}\")\n",
        "\n",
        "print(\"\\nFinal label distribution:\")\n",
        "print(df['label'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nSplit distribution:\")\n",
        "print(df['split'].value_counts())\n",
        "\n",
        "# Create separate DataFrames for each split\n",
        "train_df = df[df['split'] == 'train'][['filename', 'label']].copy()\n",
        "test_df = df[df['split'] == 'test'][['filename', 'label']].copy()\n",
        "val_df = df[df['split'] == 'val'][['filename', 'label']].copy()\n",
        "\n",
        "print(\"\\nFinal split sizes:\")\n",
        "print(f\"Train: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"Test:  {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"Val:   {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\nLabel distribution per split:\")\n",
        "for split_name, split_df in [('Train', train_df), ('Test', test_df), ('Val', val_df)]:\n",
        "    print(f\"\\n{split_name}:\")\n",
        "    class_counts = split_df['label'].value_counts().sort_index()\n",
        "    for label in sorted(split_df['label'].unique()):\n",
        "        count = class_counts[label]\n",
        "        percentage = count / len(split_df) * 100\n",
        "        original_class = label + 3  # Convert back to original class for display\n",
        "        print(f\"  Label {label} (orig. class {original_class}): {count} samples ({percentage:.1f}%)\")\n",
        "\n",
        "# Save final CSV files\n",
        "slices = [\n",
        "    ('train', train_df),\n",
        "    ('test', test_df),\n",
        "    ('val', val_df)\n",
        "]\n",
        "\n",
        "for split_name, split_df in slices:\n",
        "    out_path = f\"{split_name}{output_suffix}\"\n",
        "    split_df.to_csv(out_path, index=False)\n",
        "    print(f\"Saved: {out_path}\")\n",
        "\n",
        "print(\"\\nSuccessfully created final train/test/val splits!\")\n",
        "print(\"Classes 0–2 removed, remaining classes remapped to 0–4.\")\n",
        "print(f\"Number of classes in final dataset: {df['label'].nunique()}\")\n",
        "print(f\"All files saved with suffix: {output_suffix}\")\n",
        "\n",
        "# Validate labels\n",
        "print(\"\\n=== Label analysis ===\")\n",
        "print(f\"Original class values: {sorted(df['class'].unique())}\")\n",
        "print(f\"Current label values: {sorted(df['label'].unique())}\")\n",
        "print(f\"Label range: {df['label'].min()} to {df['label'].max()}\")\n",
        "\n",
        "min_label = df['label'].min()\n",
        "max_label = df['label'].max()\n",
        "unique_labels = sorted(df['label'].unique())\n",
        "\n",
        "print(f\"Number of unique labels: {len(unique_labels)}\")\n",
        "print(f\"Labels are continuous: {unique_labels == list(range(min_label, max_label + 1))}\")\n",
        "\n",
        "# Fix labels if needed\n",
        "if min_label != 0:\n",
        "    print(f\"Warning: Labels start from {min_label}, remapping to start from 0...\")\n",
        "    label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
        "    df['label'] = df['label'].map(label_mapping)\n",
        "\n",
        "    print(f\"New label mapping: {label_mapping}\")\n",
        "    print(f\"New label range: {df['label'].min()} to {df['label'].max()}\")\n",
        "\n",
        "    # Update train/test/val dataframes\n",
        "    for split_name, split_df in [('train', train_df), ('test', test_df), ('val', val_df)]:\n",
        "        updated_labels = []\n",
        "        for filename in split_df['filename']:\n",
        "            updated_label = df[df['filename'] == filename]['label'].iloc[0]\n",
        "            updated_labels.append(updated_label)\n",
        "        split_df['label'] = updated_labels\n",
        "        out_path = os.path.join(output_dir, f\"{split_name}{output_suffix}\")\n",
        "        split_df.to_csv(out_path, index=False)\n",
        "        print(f\"Updated and saved: {out_path}\")\n",
        "\n",
        "    print(\"All labels have been remapped to start from 0.\")\n",
        "else:\n",
        "    print(\"Labels already start from 0 – no remapping needed.\")\n",
        "\n",
        "print(\"\\n=== Final label summary ===\")\n",
        "print(f\"Label range: {df['label'].min()} to {df['label'].max()}\")\n",
        "print(f\"Number of classes: {df['label'].nunique()}\")\n",
        "print(f\"Unique labels: {sorted(df['label'].unique())}\")\n",
        "print(\"=== End label analysis ===\\n\")\n"
      ],
      "metadata": {
        "id": "nV5NWaczenWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset"
      ],
      "metadata": {
        "id": "RqqZsaake0M_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CropDatasetFromCSV(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for loading multi-band .npy images from a CSV file.\n",
        "\n",
        "    CSV file must contain:\n",
        "    - 'filename': path to .npy file (relative to image_dir)\n",
        "    - 'label': integer class label\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_file, image_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Validate and fix labels\n",
        "        print(f\"Original label range: {self.data['label'].min()} to {self.data['label'].max()}\")\n",
        "        min_label = self.data['label'].min()\n",
        "        if min_label < 0:\n",
        "            print(f\"Warning: Found negative labels (min: {min_label}). Adjusting...\")\n",
        "            self.data['label'] = self.data['label'] - min_label\n",
        "\n",
        "        self.num_classes = self.data['label'].nunique()\n",
        "        max_label = self.data['label'].max()\n",
        "\n",
        "        print(f\"Adjusted label range: {self.data['label'].min()} to {max_label}\")\n",
        "        print(f\"Number of unique classes: {self.num_classes}\")\n",
        "        print(f\"Unique labels: {sorted(self.data['label'].unique())}\")\n",
        "\n",
        "        unique_labels = sorted(self.data['label'].unique())\n",
        "        if unique_labels != list(range(len(unique_labels))):\n",
        "            print(\"Warning: Labels are not continuous. Remapping...\")\n",
        "            label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
        "            self.data['label'] = self.data['label'].map(label_mapping)\n",
        "            print(f\"Remapped labels: {sorted(self.data['label'].unique())}\")\n",
        "\n",
        "        # Final validation\n",
        "        assert self.data['label'].min() >= 0, \"Labels must be non-negative\"\n",
        "        assert self.data['label'].max() < self.num_classes, f\"Labels must be < {self.num_classes}\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            filename = self.data.iloc[idx]['filename']\n",
        "            label = self.data.iloc[idx]['label']\n",
        "\n",
        "            # Validate label range\n",
        "            if label < 0 or label >= self.num_classes:\n",
        "                print(f\"Warning: Invalid label {label} at index {idx}. Clamping to valid range.\")\n",
        "                label = max(0, min(label, self.num_classes - 1))\n",
        "\n",
        "            label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "            # Load .npy image\n",
        "            path = os.path.join(self.image_dir, filename)\n",
        "            array = np.load(path)  # Shape: [Bands, H, W]\n",
        "\n",
        "            # Replace NaN/Inf values\n",
        "            array = np.nan_to_num(array, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "            tensor = torch.tensor(array, dtype=torch.float32)\n",
        "\n",
        "            # Apply transform if defined\n",
        "            if self.transform:\n",
        "                tensor = self.transform(tensor)\n",
        "\n",
        "            return tensor, label\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading file {filename} at index {idx}: {e}\")\n",
        "            dummy_tensor = torch.zeros(100, 64, 64, dtype=torch.float32)\n",
        "            dummy_label = torch.tensor(0, dtype=torch.long)\n",
        "            return dummy_tensor, dummy_label"
      ],
      "metadata": {
        "id": "2OEa4JFhe36g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Transform"
      ],
      "metadata": {
        "id": "dvQT4Lq7fxyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiBandTransform:\n",
        "    \"\"\"\n",
        "    Transformation for multi-band images:\n",
        "    - Resize to target size\n",
        "    - Random flips and rotations\n",
        "    - Optional per-band min-max normalization\n",
        "    \"\"\"\n",
        "    def __init__(self, size=224, normalize=False):\n",
        "        self.size = size\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # Resize to target size\n",
        "        x = F.interpolate(x.unsqueeze(0), size=(self.size, self.size), mode='bilinear', align_corners=False)\n",
        "        x = x.squeeze(0)\n",
        "\n",
        "        # Random flips and rotation\n",
        "        if random.random() > 0.5:\n",
        "            x = TF.hflip(x)\n",
        "        if random.random() > 0.5:\n",
        "            x = TF.vflip(x)\n",
        "        if random.random() > 0.5:\n",
        "            x = TF.rotate(x, angle=90)\n",
        "\n",
        "        # Optional normalization\n",
        "        if self.normalize:\n",
        "            min_vals = x.amin(dim=(1, 2), keepdim=True)\n",
        "            max_vals = x.amax(dim=(1, 2), keepdim=True)\n",
        "            x = (x - min_vals) / (max_vals - min_vals + 1e-6)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "KAxmClZIf2Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataloader**"
      ],
      "metadata": {
        "id": "VU199WdJgs43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = 'stacked_patches_npy'\n",
        "train_csv = 'train_final.csv'\n",
        "val_csv = 'val_final.csv'\n",
        "test_csv = 'test_final.csv'\n",
        "\n",
        "train_transform = MultiBandTransform(size=64, normalize=True)\n",
        "val_transform = MultiBandTransform(size=64, normalize=True)\n",
        "\n",
        "print(\"=== Creating datasets with label validation ===\")\n",
        "train_dataset = CropDatasetFromCSV(train_csv, image_dir, transform=train_transform)\n",
        "val_dataset = CropDatasetFromCSV(val_csv, image_dir, transform=val_transform)\n",
        "test_dataset = CropDatasetFromCSV(test_csv, image_dir, transform=val_transform)\n",
        "\n",
        "print(\"\\nDataset sizes:\")\n",
        "print(f\"Train: {len(train_dataset)}\")\n",
        "print(f\"Val: {len(val_dataset)}\")\n",
        "print(f\"Test: {len(test_dataset)}\")\n",
        "print(f\"Number of classes (train): {train_dataset.num_classes}\")\n",
        "print(f\"Number of classes (val): {val_dataset.num_classes}\")\n",
        "print(f\"Number of classes (test): {test_dataset.num_classes}\")\n",
        "\n",
        "assert train_dataset.num_classes == val_dataset.num_classes == test_dataset.num_classes, \\\n",
        "    \"All datasets must have the same number of classes\"\n",
        "\n",
        "num_workers = 0 if platform.system() == 'Windows' else 2\n",
        "print(f\"Using num_workers={num_workers} for DataLoader\")\n",
        "\n",
        "try:\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=num_workers, pin_memory=False)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=num_workers, pin_memory=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=num_workers, pin_memory=False)\n",
        "    print(\"DataLoaders created successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating DataLoaders with num_workers={num_workers}, falling back to num_workers=0\")\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=False)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0, pin_memory=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0, pin_memory=False)\n",
        "    print(\"DataLoaders created with num_workers=0.\")\n",
        "\n",
        "print(\"=== Dataset creation complete ===\")\n",
        "\n",
        "# Example batch\n",
        "batch = next(iter(train_loader))\n",
        "images, labels = batch\n",
        "print(\"Batch shape:\", images.shape)\n",
        "print(\"Batch values (min, max):\", images.min().item(), images.max().item())"
      ],
      "metadata": {
        "id": "dyC8VTQogsbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data augmentation visualization**"
      ],
      "metadata": {
        "id": "awwoP369g5cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_aug = MultiBandTransform(size=224, normalize=False)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "for i, band in enumerate([0, 50, 69]):\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    plt.imshow(images[0][band], cmap='gray')\n",
        "    plt.title(f'Original Band {band}')\n",
        "    plt.axis('off')\n",
        "plt.suptitle('Before Augmentation')\n",
        "plt.show()\n",
        "\n",
        "sample_aug = transform_aug(images[0])\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "for i, band in enumerate([0, 50, 69]):\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    plt.imshow(sample_aug[band], cmap='gray')\n",
        "    plt.title(f'Augmented Band {band}')\n",
        "    plt.axis('off')\n",
        "plt.suptitle('After Augmentation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kA0necTug-FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50"
      ],
      "metadata": {
        "id": "_RSh802VBrXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition and training pipeline\n",
        "# Note: Using CPU due to CUDA context corruption. To enable GPU, restart the kernel.\n",
        "\n",
        "print(\"Creating model on CPU due to CUDA context corruption.\")\n",
        "print(\"To fix CUDA issues: restart the kernel and rerun all cells.\")\n",
        "\n",
        "class CustomResNet50(nn.Module):\n",
        "    \"\"\"\n",
        "    Custom ResNet-50 model with adjustable input channels and number of classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=70, num_classes=5):\n",
        "        super().__init__()\n",
        "        self.model = resnet50(weights=None)\n",
        "\n",
        "        # Replace first convolutional layer for multi-band input\n",
        "        self.model.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "        # Replace classification head\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Instantiate model\n",
        "num_classes = train_dataset.num_classes\n",
        "print(f\"Creating model with {num_classes} classes.\")\n",
        "model = CustomResNet50(in_channels=70, num_classes=num_classes).to(device)\n",
        "print(f\"Model created successfully with {num_classes} output classes.\")\n",
        "print(f\"Model output classes: {model.model.fc.out_features}\")\n",
        "\n",
        "print(\"\\nIMPORTANT: To use CUDA again:\")\n",
        "print(\"1. Restart the kernel\")\n",
        "print(\"2. Rerun all cells from the beginning\")\n",
        "print(\"3. Change device back to 'cuda' in training configuration\")\n",
        "\n",
        "\n",
        "# Inspect one batch of data\n",
        "batch = next(iter(train_loader))\n",
        "images, labels = batch\n",
        "print(\"Image batch shape:\", images.shape)   # e.g. [16, 70, 224, 224]\n",
        "print(\"Label batch shape:\", labels.shape)\n",
        "print(\"Example label:\", labels[0])\n",
        "\n",
        "print(\"=== LABEL DEBUGGING ===\")\n",
        "all_train_labels = [train_dataset[i][1].item() for i in range(min(100, len(train_dataset)))]\n",
        "print(f\"Training labels range: {min(all_train_labels)} to {max(all_train_labels)}\")\n",
        "print(f\"Unique training labels: {sorted(set(all_train_labels))}\")\n",
        "print(f\"Expected range for {train_dataset.num_classes} classes: 0 to {train_dataset.num_classes-1}\")\n",
        "\n",
        "valid_labels = [l for l in all_train_labels if 0 <= l < train_dataset.num_classes]\n",
        "invalid_labels = [l for l in all_train_labels if l < 0 or l >= train_dataset.num_classes]\n",
        "print(f\"Valid labels count: {len(valid_labels)}\")\n",
        "print(f\"Invalid labels: {invalid_labels}\")\n",
        "\n",
        "if invalid_labels:\n",
        "    print(\"WARNING: Invalid labels detected! Labels must be in range [0, num_classes-1].\")\n",
        "else:\n",
        "    print(\"All training labels are valid.\")\n",
        "\n",
        "# Validation label check\n",
        "all_val_labels = [val_dataset[i][1].item() for i in range(min(200, len(val_dataset)))]\n",
        "print(f\"Validation labels range: {min(all_val_labels)} to {max(all_val_labels)}\")\n",
        "print(f\"Unique validation labels: {sorted(set(all_val_labels))}\")\n",
        "print(\"=== END LABEL DEBUGGING ===\\n\")\n",
        "\n",
        "\n",
        "# Visualize selected image bands\n",
        "img = images[0]\n",
        "for i in [0, 50, 69]:  # Select example bands\n",
        "    plt.imshow(img[i].cpu().numpy(), cmap=\"gray\")\n",
        "    plt.title(f\"Channel {i}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "txEdrkaLBaX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trainings Loop**"
      ],
      "metadata": {
        "id": "45rxjeCgB1io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_settings_with_tensorboard(model, epochs, device, optimizer,\n",
        "                                       criterion, train_dataloader, val_dataloader,\n",
        "                                       weights_name, log_dir=\"runs\", weights_dir=\"model_weights\",\n",
        "                                       run_name=None, writer=None):\n",
        "    \"\"\"\n",
        "    Train and validate a model with TensorBoard logging.\n",
        "    Logs include loss, accuracy, and F1 score for both training and validation.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Model to train.\n",
        "        epochs (int): Number of training epochs.\n",
        "        device (str): Device ('cpu' or 'cuda').\n",
        "        optimizer (torch.optim.Optimizer): Optimizer.\n",
        "        criterion: Loss function.\n",
        "        train_dataloader (DataLoader): Training data loader.\n",
        "        val_dataloader (DataLoader): Validation data loader.\n",
        "        weights_name (str): Base filename for saving weights.\n",
        "        log_dir (str): Directory for TensorBoard logs.\n",
        "        weights_dir (str): Directory for saving model weights.\n",
        "        run_name (str): Optional run identifier for logs.\n",
        "        writer (SummaryWriter): Optional shared SummaryWriter.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Lists of train_losses, val_losses, train_accuracy,\n",
        "               val_accuracy, train_f1_scores, val_f1_scores\n",
        "    \"\"\"\n",
        "    own_writer = writer is None\n",
        "    if own_writer:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        log_path = f\"{log_dir}/{run_name}_{timestamp}\" if run_name else f\"{log_dir}/crop_classification_{timestamp}\"\n",
        "        writer = SummaryWriter(log_path)\n",
        "    else:\n",
        "        log_path = writer.log_dir\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    trn_accuracy, val_accuracy = [], []\n",
        "    train_f1_scores, val_f1_scores = [], []\n",
        "\n",
        "    num_classes = model.model.fc.out_features\n",
        "    print(f\"Model expects {num_classes} classes.\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
        "        train_predictions, train_true_labels = [], []\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_dataloader):\n",
        "            try:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels.long())\n",
        "                if torch.isnan(loss):\n",
        "                    print(f\"NaN loss at epoch {epoch}, batch {batch_idx}. Skipping batch.\")\n",
        "                    continue\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                train_total += labels.size(0)\n",
        "                train_correct += (predicted == labels).sum().item()\n",
        "                train_predictions.extend(predicted.cpu().numpy())\n",
        "                train_true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                if batch_idx % 10 == 0:\n",
        "                    tag_prefix = f\"{run_name}/\" if run_name and not own_writer else \"\"\n",
        "                    writer.add_scalar(f\"{tag_prefix}Loss/Train_Batch\", loss.item(),\n",
        "                                      epoch * len(train_dataloader) + batch_idx)\n",
        "            except RuntimeError as e:\n",
        "                print(f\"RuntimeError in training (epoch {epoch}, batch {batch_idx}): {e}\")\n",
        "                raise e\n",
        "\n",
        "        if train_total > 0:\n",
        "            train_loss /= len(train_dataloader)\n",
        "            train_acc = 100.0 * train_correct / train_total\n",
        "            train_f1 = f1_score(train_true_labels, train_predictions, average=\"weighted\") * 100\n",
        "            train_losses.append(train_loss)\n",
        "            trn_accuracy.append(train_acc)\n",
        "            train_f1_scores.append(train_f1)\n",
        "        else:\n",
        "            print(f\"No valid training samples in epoch {epoch}.\")\n",
        "            continue\n",
        "\n",
        "        # Validation Phase\n",
        "        model.eval()\n",
        "        valid_loss, valid_correct, valid_total = 0.0, 0, 0\n",
        "        val_predictions, val_true_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, labels) in enumerate(val_dataloader):\n",
        "                try:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    if torch.any(labels < 0) or torch.any(labels >= num_classes):\n",
        "                        print(f\"Invalid validation labels in batch {batch_idx}. Clamping values.\")\n",
        "                        labels = torch.clamp(labels, 0, num_classes - 1)\n",
        "\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels.long())\n",
        "                    if torch.isnan(loss):\n",
        "                        print(f\"NaN validation loss at epoch {epoch}, batch {batch_idx}. Skipping batch.\")\n",
        "                        continue\n",
        "\n",
        "                    valid_loss += loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    valid_total += labels.size(0)\n",
        "                    valid_correct += (predicted == labels).sum().item()\n",
        "                    val_predictions.extend(predicted.cpu().numpy())\n",
        "                    val_true_labels.extend(labels.cpu().numpy())\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"RuntimeError in validation (epoch {epoch}, batch {batch_idx}): {e}\")\n",
        "                    raise e\n",
        "\n",
        "        if valid_total > 0:\n",
        "            valid_loss /= len(val_dataloader)\n",
        "            val_acc = 100.0 * valid_correct / valid_total\n",
        "            val_f1 = f1_score(val_true_labels, val_predictions, average=\"weighted\") * 100\n",
        "            val_losses.append(valid_loss)\n",
        "            val_accuracy.append(val_acc)\n",
        "            val_f1_scores.append(val_f1)\n",
        "        else:\n",
        "            print(f\"No valid validation samples in epoch {epoch}.\")\n",
        "            continue\n",
        "\n",
        "        # === Logging ===\n",
        "        tag_prefix = f\"{run_name}/\" if run_name and not own_writer else \"\"\n",
        "        writer.add_scalar(f\"{tag_prefix}Loss/Train_Epoch\", train_loss, epoch)\n",
        "        writer.add_scalar(f\"{tag_prefix}Loss/Validation_Epoch\", valid_loss, epoch)\n",
        "        writer.add_scalar(f\"{tag_prefix}Accuracy/Train\", train_acc, epoch)\n",
        "        writer.add_scalar(f\"{tag_prefix}Accuracy/Validation\", val_acc, epoch)\n",
        "        writer.add_scalar(f\"{tag_prefix}F1_Score/Train\", train_f1, epoch)\n",
        "        writer.add_scalar(f\"{tag_prefix}F1_Score/Validation\", val_f1, epoch)\n",
        "        writer.add_scalar(f\"{tag_prefix}Learning_Rate\", optimizer.param_groups[0][\"lr\"], epoch)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%, F1: {train_f1:.2f}% | \"\n",
        "              f\"Val Loss: {valid_loss:.4f}, Acc: {val_acc:.2f}%, F1: {val_f1:.2f}%\")\n",
        "\n",
        "        torch.save(model.state_dict(), f\"{weights_dir}/{weights_name}_epoch_{epoch}.pt\")\n",
        "\n",
        "    if own_writer:\n",
        "        writer.close()\n",
        "        print(f\"TensorBoard logs saved to: {log_path}\")\n",
        "    else:\n",
        "        print(\"Metrics logged to shared writer.\")\n",
        "\n",
        "    return train_losses, val_losses, trn_accuracy, val_accuracy, train_f1_scores, val_f1_scores"
      ],
      "metadata": {
        "id": "jr9IUlzNByEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Training"
      ],
      "metadata": {
        "id": "IDZQ9DafGCjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_weights_name = \"best_model_weights_v2\"\n",
        "current_device = next(model.parameters()).device  # Get device from model\n",
        "print(f\"Training will run on: {current_device}\")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 15  # Reduced for CPU training\n",
        "\n",
        "print(\"=== PRE-TRAINING VALIDATION ===\")\n",
        "print(f\"Model device: {current_device}\")\n",
        "print(f\"Model output classes: {model.model.fc.out_features}\")\n",
        "print(f\"Training dataset classes: {train_dataset.num_classes}\")\n",
        "print(f\"Validation dataset classes: {val_dataset.num_classes}\")\n",
        "\n",
        "# Verify model and data compatibility\n",
        "if model.model.fc.out_features == train_dataset.num_classes:\n",
        "    print(\"Model and dataset classes match!\")\n",
        "else:\n",
        "    print(f\"ERROR: Model expects {model.model.fc.out_features} \"\n",
        "          f\"classes but dataset has {train_dataset.num_classes}\")\n",
        "\n",
        "print(\"=== READY TO START TRAINING ===\")\n",
        "print(\"Training on CPU will be slower than GPU\")\n",
        "print(\"To use GPU: Restart kernel and rerun all cells\")\n"
      ],
      "metadata": {
        "id": "uqNazzKJGHsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start Training"
      ],
      "metadata": {
        "id": "gCGaMr8gTUQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses, train_acc, val_acc, train_f1_scores, val_f1_scores = training_settings_with_tensorboard(\n",
        "    model=model,\n",
        "    epochs=epochs,\n",
        "    device=current_device,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    train_dataloader=train_loader,\n",
        "    val_dataloader=val_loader,\n",
        "    weights_name=model_weights_name,\n",
        "    log_dir=\"tensorboard_logs\"\n",
        ")\n",
        "\n",
        "\n",
        "# Training Progress Visualization\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Slice from index 1 to skip epoch 0\n",
        "train_losses_plot = train_losses[1:] if len(train_losses) > 1 else train_losses\n",
        "val_losses_plot = val_losses[1:] if len(val_losses) > 1 else val_losses\n",
        "train_acc_plot = train_acc[1:] if len(train_acc) > 1 else train_acc\n",
        "val_acc_plot = val_acc[1:] if len(val_acc) > 1 else val_acc\n",
        "train_f1_plot = train_f1_scores[1:] if len(train_f1_scores) > 1 else train_f1_scores\n",
        "val_f1_plot = val_f1_scores[1:] if len(val_f1_scores) > 1 else val_f1_scores\n",
        "\n",
        "# Plot 1: Loss curves\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(range(2, len(train_losses) + 1), train_losses_plot, \"b-\", label=\"Training Loss\", linewidth=2)\n",
        "plt.plot(range(2, len(val_losses) + 1), val_losses_plot, \"r-\", label=\"Validation Loss\", linewidth=2)\n",
        "plt.title(\"Training and Validation Loss\", fontsize=14, fontweight=\"bold\")\n",
        "plt.xlabel(\"Epoch\", fontsize=12)\n",
        "plt.ylabel(\"Loss\", fontsize=12)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Accuracy curves\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(range(2, len(train_acc) + 1), train_acc_plot, \"b-\", label=\"Training Accuracy\", linewidth=2)\n",
        "plt.plot(range(2, len(val_acc) + 1), val_acc_plot, \"r-\", label=\"Validation Accuracy\", linewidth=2)\n",
        "plt.title(\"Training and Validation Accuracy\", fontsize=14, fontweight=\"bold\")\n",
        "plt.xlabel(\"Epoch\", fontsize=12)\n",
        "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: F1 Score curves\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(range(2, len(train_f1_scores) + 1), train_f1_plot, \"b-\", label=\"Training F1\", linewidth=2)\n",
        "plt.plot(range(2, len(val_f1_scores) + 1), val_f1_plot, \"r-\", label=\"Validation F1\", linewidth=2)\n",
        "plt.title(\"Training and Validation F1 Score\", fontsize=14, fontweight=\"bold\")\n",
        "plt.xlabel(\"Epoch\", fontsize=12)\n",
        "plt.ylabel(\"F1 Score (%)\", fontsize=12)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Overview\n",
        "plt.subplot(2, 2, 4)\n",
        "epochs_range = range(2, len(train_losses) + 1)\n",
        "plt.plot(epochs_range, train_losses_plot, \"b-\", alpha=0.7, label=\"Train Loss\")\n",
        "plt.plot(epochs_range, val_losses_plot, \"r-\", alpha=0.7, label=\"Val Loss\")\n",
        "\n",
        "# Normalize accuracy/F1 to same scale as loss\n",
        "norm_train_acc = [acc / 100 for acc in train_acc_plot]\n",
        "norm_val_acc = [acc / 100 for acc in val_acc_plot]\n",
        "norm_train_f1 = [f1 / 100 for f1 in train_f1_plot]\n",
        "norm_val_f1 = [f1 / 100 for f1 in val_f1_plot]\n",
        "\n",
        "plt.plot(epochs_range, norm_train_acc, \"b--\", alpha=0.7, label=\"Train Acc (norm)\")\n",
        "plt.plot(epochs_range, norm_val_acc, \"r--\", alpha=0.7, label=\"Val Acc (norm)\")\n",
        "plt.plot(epochs_range, norm_train_f1, \"b:\", alpha=0.7, label=\"Train F1 (norm)\")\n",
        "plt.plot(epochs_range, norm_val_f1, \"r:\", alpha=0.7, label=\"Val F1 (norm)\")\n",
        "plt.title(\"Learning Curves Overview\", fontsize=14, fontweight=\"bold\")\n",
        "plt.xlabel(\"Epoch\", fontsize=12)\n",
        "plt.ylabel(\"Loss / Normalized Metrics\", fontsize=12)\n",
        "plt.legend(fontsize=9)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Final Training Stats\n",
        "\n",
        "print(\"\\nFinal Training Results:\")\n",
        "print(f\"Training Loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"Validation Loss: {val_losses[-1]:.4f}\")\n",
        "print(f\"Training Accuracy: {train_acc[-1]:.2f}%\")\n",
        "print(f\"Validation Accuracy: {val_acc[-1]:.2f}%\")\n",
        "print(f\"Training F1 Score: {train_f1_scores[-1]:.2f}%\")\n",
        "print(f\"Validation F1 Score: {val_f1_scores[-1]:.2f}%\")"
      ],
      "metadata": {
        "id": "-oU-kA7TTU9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hyperparameters**"
      ],
      "metadata": {
        "id": "I3-iwJPqTzxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def simple_hyperparameter_search(\n",
        "    train_loader, val_loader, test_loader, param_grid,\n",
        "    device=\"cpu\", results_file=\"hyperparameter_results.json\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Perform hyperparameter tuning using simple grid search with existing train/val split.\n",
        "\n",
        "    Args:\n",
        "        train_loader (DataLoader): Training DataLoader\n",
        "        val_loader (DataLoader): Validation DataLoader\n",
        "        test_loader (DataLoader): Test DataLoader\n",
        "        param_grid (dict): Dictionary of hyperparameters to search\n",
        "        device (str): Device to run on\n",
        "        results_file (str): File to save results\n",
        "\n",
        "    Returns:\n",
        "        best_params (dict): Best hyperparameter combination\n",
        "        all_results (list): All experiment results\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"HYPERPARAMETER TUNING WITH GRID SEARCH\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Generate all parameter combinations\n",
        "    param_names = list(param_grid.keys())\n",
        "    param_values = list(param_grid.values())\n",
        "    param_combinations = list(product(*param_values))\n",
        "\n",
        "    print(f\"Parameter grid: {param_grid}\")\n",
        "    print(f\"Total combinations: {len(param_combinations)}\")\n",
        "\n",
        "    # Create shared TensorBoard writer\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    shared_log_dir = f\"tensorboard_logs/hyperparameter_search_{timestamp}\"\n",
        "    shared_writer = SummaryWriter(shared_log_dir)\n",
        "    print(f\"Shared TensorBoard logs: {shared_log_dir}\")\n",
        "\n",
        "    all_results = []\n",
        "    best_score = -1\n",
        "    best_params = None\n",
        "\n",
        "    # Evaluate all parameter combinations\n",
        "    for param_idx, param_combo in enumerate(param_combinations):\n",
        "        current_params = dict(zip(param_names, param_combo))\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Testing combination {param_idx + 1}/{len(param_combinations)}: {current_params}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        try:\n",
        "            # Initialize model\n",
        "            model = CustomResNet50().to(device)\n",
        "\n",
        "            # Setup optimizer\n",
        "            if current_params[\"optimizer\"] == \"adam\":\n",
        "                optimizer = torch.optim.Adam(\n",
        "                    model.parameters(),\n",
        "                    lr=current_params[\"learning_rate\"],\n",
        "                    weight_decay=current_params.get(\"weight_decay\", 0)\n",
        "                )\n",
        "            elif current_params[\"optimizer\"] == \"sgd\":\n",
        "                optimizer = torch.optim.SGD(\n",
        "                    model.parameters(),\n",
        "                    lr=current_params[\"learning_rate\"],\n",
        "                    momentum=current_params.get(\"momentum\", 0.9),\n",
        "                    weight_decay=current_params.get(\"weight_decay\", 0)\n",
        "                )\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            # Adjust batch size if needed\n",
        "            if current_params[\"batch_size\"] != train_loader.batch_size:\n",
        "                current_train_loader = DataLoader(\n",
        "                    train_loader.dataset,\n",
        "                    batch_size=current_params[\"batch_size\"],\n",
        "                    shuffle=True\n",
        "                )\n",
        "                current_val_loader = DataLoader(\n",
        "                    val_loader.dataset,\n",
        "                    batch_size=current_params[\"batch_size\"],\n",
        "                    shuffle=False\n",
        "                )\n",
        "            else:\n",
        "                current_train_loader = train_loader\n",
        "                current_val_loader = val_loader\n",
        "\n",
        "            # Define run name\n",
        "            run_name = (\n",
        "                f\"hparam_{param_idx}_lr{current_params['learning_rate']}_\"\n",
        "                f\"bs{current_params['batch_size']}_opt{current_params['optimizer']}_\"\n",
        "                f\"ep{current_params['epochs']}\"\n",
        "            )\n",
        "\n",
        "            # Train model\n",
        "            train_losses, val_losses, train_acc, val_acc, train_f1, val_f1 = training_settings_with_tensorboard(\n",
        "                model=model,\n",
        "                epochs=current_params[\"epochs\"],\n",
        "                device=device,\n",
        "                optimizer=optimizer,\n",
        "                criterion=criterion,\n",
        "                train_dataloader=current_train_loader,\n",
        "                val_dataloader=current_val_loader,\n",
        "                weights_name=f\"hyperparam_search_{param_idx}\",\n",
        "                run_name=run_name,\n",
        "                writer=shared_writer\n",
        "            )\n",
        "\n",
        "            # Collect results\n",
        "            result = {\n",
        "                \"params\": current_params,\n",
        "                \"final_train_loss\": train_losses[-1] if train_losses else float(\"inf\"),\n",
        "                \"final_val_loss\": val_losses[-1] if val_losses else float(\"inf\"),\n",
        "                \"final_train_acc\": train_acc[-1] if train_acc else 0,\n",
        "                \"final_val_acc\": val_acc[-1] if val_acc else 0,\n",
        "                \"final_train_f1\": train_f1[-1] if train_f1 else 0,\n",
        "                \"final_val_f1\": val_f1[-1] if val_f1 else 0,\n",
        "                \"max_val_acc\": max(val_acc) if val_acc else 0,\n",
        "                \"max_val_f1\": max(val_f1) if val_f1 else 0,\n",
        "                \"score\": max(val_acc) if val_acc else 0\n",
        "            }\n",
        "            all_results.append(result)\n",
        "\n",
        "            # Track best parameters\n",
        "            if result[\"score\"] > best_score:\n",
        "                best_score = result[\"score\"]\n",
        "                best_params = current_params.copy()\n",
        "                print(f\"New best parameters found. Score: {best_score:.2f}%\")\n",
        "\n",
        "            # Save intermediate results\n",
        "            with open(results_file, \"w\") as f:\n",
        "                json.dump({\n",
        "                    \"best_params\": best_params,\n",
        "                    \"best_score\": best_score,\n",
        "                    \"all_results\": [\n",
        "                        {k: v for k, v in r.items() if k not in [\n",
        "                            \"train_losses\", \"val_losses\", \"train_acc\", \"val_acc\", \"train_f1\", \"val_f1\"\n",
        "                        ]}\n",
        "                        for r in all_results\n",
        "                    ]\n",
        "                }, f, indent=2)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in experiment {param_idx + 1}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            all_results.append({\"params\": current_params, \"error\": str(e), \"score\": 0})\n",
        "\n",
        "    # Final reporting\n",
        "    all_results.sort(key=lambda x: x.get(\"score\", 0), reverse=True)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"HYPERPARAMETER TUNING COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "    print(f\"Best Score: {best_score:.2f}%\")\n",
        "\n",
        "    shared_writer.close()\n",
        "    print(f\"TensorBoard writer closed. Logs available at {shared_log_dir}\")\n",
        "\n",
        "    return best_params, all_results"
      ],
      "metadata": {
        "id": "zOSFATmLTyzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Grid Definition"
      ],
      "metadata": {
        "id": "fPggO5LxZYA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameter_grid = {\n",
        "    \"learning_rate\": [0.0001, 0.0005],\n",
        "    \"batch_size\": [16, 32],\n",
        "    \"optimizer\": [\"adam\"],\n",
        "    \"weight_decay\": [0.001],\n",
        "    \"epochs\": [20, 30, 50],\n",
        "}\n",
        "\n",
        "print(\"Hyperparameter Grid:\")\n",
        "for param, values in hyperparameter_grid.items():\n",
        "    print(f\"  {param}: {values}\")\n",
        "\n",
        "total_combinations = 1\n",
        "for values in hyperparameter_grid.values():\n",
        "    total_combinations *= len(values)\n",
        "print(f\"Total combinations to test: {total_combinations}\")"
      ],
      "metadata": {
        "id": "RBQhrkxnZi2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Search"
      ],
      "metadata": {
        "id": "HLd_JPDbZoUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    best_params, all_results = simple_hyperparameter_search(\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        test_loader=test_loader,\n",
        "        param_grid=hyperparameter_grid,\n",
        "        device=\"cuda:0\",\n",
        "        results_file=\"simple_hyperparameter_results.json\"\n",
        "    )\n",
        "    print(\"Hyperparameter tuning completed successfully.\")\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during hyperparameter tuning: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "snHiumjxZsiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix"
      ],
      "metadata": {
        "id": "Eroq-aT3ZxJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "# Create visualization\n",
        "plt.figure(figsize=(10, 8))\n",
        "im = plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "\n",
        "# Add colorbar\n",
        "cbar = plt.colorbar(im, shrink=0.8)\n",
        "cbar.set_label('Number of Predictions', rotation=270, labelpad=20, fontsize=12)\n",
        "\n",
        "# Title and axis labels\n",
        "plt.title(\n",
        "    'Confusion Matrix - Crop Classification\\n(ResNet-50 with 100 Spectral Bands)',\n",
        "    fontsize=16,\n",
        "    fontweight='bold',\n",
        "    pad=20\n",
        ")\n",
        "class_names = [f'Class {i}' for i in range(5)]\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names, fontsize=11)\n",
        "plt.yticks(tick_marks, class_names, fontsize=11)\n",
        "plt.xlabel('Predicted Class', fontsize=13, fontweight='bold')\n",
        "plt.ylabel('True Class', fontsize=13, fontweight='bold')\n",
        "\n",
        "# Add annotations (counts and percentages)\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        percentage = cm[i, j] / cm[i, :].sum() * 100 if cm[i, :].sum() > 0 else 0\n",
        "        text_color = \"white\" if cm[i, j] > thresh else \"black\"\n",
        "        plt.text(\n",
        "            j, i,\n",
        "            f'{cm[i, j]}\\n({percentage:.1f}%)',\n",
        "            ha=\"center\", va=\"center\",\n",
        "            color=text_color,\n",
        "            fontsize=10,\n",
        "            fontweight='bold'\n",
        "        )\n",
        "\n",
        "# Add grid lines for readability\n",
        "for i in range(len(class_names)):\n",
        "    plt.axhline(i - 0.5, color='white', linewidth=2)\n",
        "    plt.axvline(i - 0.5, color='white', linewidth=2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print classification report summary\n",
        "print(\"=\" * 60)\n",
        "print(\"DETAILED CLASSIFICATION REPORT\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total Test Samples: {len(true_labels)}\")\n",
        "print(f\"Correct Predictions: {np.trace(cm)}\")\n",
        "print(f\"Incorrect Predictions: {len(true_labels) - np.trace(cm)}\")"
      ],
      "metadata": {
        "id": "lbWIRQqkZ2DY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}